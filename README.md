# ğŸ¤Ÿ Sign Language Recognition (Proyecto IA Final)

Este repositorio contiene la implementaciÃ³n de un sistema de reconocimiento de lenguaje de seÃ±as basado en visiÃ³n por computadora y aprendizaje automÃ¡tico, utilizando MediaPipe y TensorFlow.

---

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ asl_model.h5           # Modelo entrenado con imÃ¡genes (opcional)
â”‚   â”‚   â”œâ”€â”€ landmarks_model.h5     # Modelo entrenado con vectores de manos
â”‚   â”‚   â””â”€â”€ label_classes.npy      # Clases codificadas
â”‚   â”œâ”€â”€ app.py                     # API principal con Flask
â”‚   â”œâ”€â”€ app_test1.py               # Variante para pruebas
â”‚   â””â”€â”€ requirements.txt           # LibrerÃ­as necesarias
â”‚
â”œâ”€â”€ frontend/templates/
â”‚   â””â”€â”€ index.html                 # Interfaz de usuario (HTML + JS)
â”‚
â”œâ”€â”€ capture_landmarks.py          # Captura vectores desde webcam
â”œâ”€â”€ landmark_dataset.csv          # Dataset generado con vectores
â”œâ”€â”€ train_model.py                # Entrena modelo desde imÃ¡genes (opcional)
â”œâ”€â”€ train_landmark_model.py       # Entrena modelo desde vectores
â”œâ”€â”€ .gitignore
â””â”€â”€ .gitattributes
```

---

## âš™ï¸ InstalaciÃ³n

1. Clona este repositorio:

```bash
git clone https://github.com/Dart18-80/ProyectoIAFinal.git
cd ProyectoIAFinal
```

2. (Opcional) Crea y activa un entorno virtual:

```bash
python -m venv venv
source venv/Scripts/activate  # Windows
```

3. Instala los requerimientos:

```bash
pip install -r backend/requirements.txt
```

---

## ğŸ§ª Flujo de trabajo

### 1. Captura de vectores (landmarks)

```bash
python capture_landmarks.py
```

Sigue las instrucciones en consola para capturar ejemplos por cada letra o gesto.

### 2. Entrenamiento del modelo

```bash
python train_landmark_model.py
```

Esto generarÃ¡ `landmarks_model.h5` y `label_classes.npy` dentro de `backend/model`.

### 3. EjecuciÃ³n del sistema

```bash
python backend/app.py
```

Luego abre `frontend/templates/index.html` en tu navegador.

---

## ğŸ¯ Funcionalidad

* Detecta manos en tiempo real usando MediaPipe.
* Extrae los 21 landmarks por frame.
* Clasifica el gesto utilizando un modelo `Keras` entrenado.
* Muestra la letra o palabra predicha en pantalla con su porcentaje de confianza.

---

## ğŸ’  TecnologÃ­as utilizadas

* Python 3.10
* Flask
* TensorFlow / Keras
* MediaPipe
* NumPy
* OpenCV
* HTML / JS (Vanilla)

---

## ğŸ“ Notas

* Es importante capturar al menos 50â€“100 ejemplos por clase.
* Las etiquetas deben coincidir con las que fueron usadas al entrenar.
* Para mejor precisiÃ³n, asegÃºrate de usar buena iluminaciÃ³n y la misma mano (derecha o izquierda) con consistencia.

---

## ğŸ§  CrÃ©ditos

Proyecto acadÃ©mico desarrollado como entrega final del curso de Inteligencia Artificial.
Autores: Diego Ruiz (1037419) y Fernanda Caneses (1187820)
